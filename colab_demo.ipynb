{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba0fd7e",
   "metadata": {},
   "source": [
    "# RWKV-7 TTT Phantom Colab\n",
    "\n",
    "This notebook demonstrates training and generation with the RWKV-7 TTT Phantom model using a single NVIDIA A100 40GB GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0d817",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Clone the repository and install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/USER/RWKV-7-TTT-Phantom.git\n",
    "%cd RWKV-7-TTT-Phantom\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49740d4d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Define a configuration that comfortably fits on a 40GB GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwkv7_ttt_phantom import RWKV7PhantomConfig\n",
    "\n",
    "config = RWKV7PhantomConfig(\n",
    "    n_layer=12,\n",
    "    n_embd=768,\n",
    "    n_head=12,\n",
    "    head_size=64,\n",
    "    vocab_size=65536,\n",
    "    ghost_ratio=0.75,\n",
    "    core_ratio=0.25,\n",
    "    ttt_enabled=True,\n",
    "    ttt_lr=0.01,\n",
    "    ttt_steps=1,\n",
    "    max_depth_iter=1,\n",
    "    use_svd_compression=True,\n",
    "    svd_rank_ratio=0.5,\n",
    "    use_sparsity=True,\n",
    "    sparsity_ratio=0.3,\n",
    ")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a346ab2",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "The training script expects tokenized data in `.bin`/`.idx` format. The cell below creates a tiny random dataset for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "# Random tokens for example\n",
    "tokens = np.random.randint(0, config.vocab_size, size=10000, dtype=np.uint16)\n",
    "with open(\"data/dummy.bin\", \"wb\") as f:\n",
    "    f.write(tokens.tobytes())\n",
    "\n",
    "# Simple sequential indices with chunk size 512\n",
    "idx = np.arange(0, len(tokens)+1, 512, dtype=np.int64)\n",
    "with open(\"data/dummy.idx\", \"wb\") as f:\n",
    "    f.write(idx.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625356fc",
   "metadata": {},
   "source": [
    "## Training\n",
    "Run `train_model` to train on the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9391b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training import train_model\n",
    "\n",
    "model = train_model(\n",
    "    data_path=\"data/dummy\",\n",
    "    output_dir=\"./output\",\n",
    "    config=config,\n",
    "    batch_size=2,\n",
    "    learning_rate=6e-4,\n",
    "    num_epochs=1,\n",
    "    use_wandb=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101414a9",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "Generate text using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b2293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "prompt = torch.tensor([[1, 2, 3]])\n",
    "print(model.model.generate(prompt, max_new_tokens=20))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
